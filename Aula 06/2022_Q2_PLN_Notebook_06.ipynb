{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2022-Q2 PLN Notebook 06.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalves-ufabc/2022.Q2-PLN/blob/main/2022_Q2_PLN_Notebook_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q2Bo6Sill63"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2022.Q2]**\n",
        "\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rhi4TLwolnvK"
      },
      "source": [
        "##**Modelo de Linguagem com N-gramas**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYPYP6mVSTVk"
      },
      "source": [
        "### **Bibliotecas**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFeFaUQEtEqC"
      },
      "source": [
        "# expressoes regulares\n",
        "import re\n",
        "\n",
        "# cria um dicinario com a frequencia dos termos em um iterable\n",
        "from collections import Counter\n",
        "\n",
        "## subsequencias de um iterable\n",
        "from itertools import islice\n",
        "\n",
        "# numeros e sequencias aleatoreas\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1K0PgaCSx_U"
      },
      "source": [
        "### **Funções principais**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SA9JstDuVaL"
      },
      "source": [
        "regex = r\"[-'a-zA-ZÀ-ÖØ-öø-ÿ]+\"       # raw string\n",
        "#regex = r\"[-'a-zA-ZÀ-ÖØ-öø-ÿ0-9]+\"   # raw string\n",
        "\n",
        "# usa expressoes regulares para quebrar um texto em tokens\n",
        "def get_tokens(fileName):\n",
        "  # leitura do documento\n",
        "  with open(fileName,'r') as document:\n",
        "     content  = document.read()  # devolve um vetor contendo as linhas do arquivo\n",
        "     content  = content.lower()\n",
        "\n",
        "  Words    = re.findall(regex, content)\n",
        "\n",
        "  return(Words)\n",
        "\n",
        "# similar ao get_tokens, mas removindo elementos da lista de stopwords\n",
        "def get_tokens_without_stopwords(fileName,stopwordsName=\"/content/stopwords.txt\"):\n",
        "   # leitura do documento\n",
        "   with open(fileName,'r') as document:\n",
        "      content  = document.read()  # devolve um vetor contendo as linhas do arquivo\n",
        "      content  = content.lower()\n",
        "\n",
        "   # leitura das stopwords\n",
        "   with open(stopwordsName,'r') as stopwordsfile:\n",
        "      stopwords = set([])\n",
        "      for s in stopwordsfile.readlines():                                                                                                                                                     \n",
        "        stopwords.add(s.strip().lower())\n",
        "\n",
        "   # remove as stopwords\n",
        "   Words    = [w for w in re.findall(regex, content) if w not in stopwords]\n",
        "\n",
        "   return(Words)\n",
        "\n",
        "# retirado de um exemplo na internet\n",
        "def window(seq, n=2):\n",
        "    \"Retorna uma janela deslizante (de tamanho n) sobre a sequencia seq\"\n",
        "    \"   s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   \"\n",
        "    it = iter(seq)\n",
        "    result = tuple(islice(it, n))\n",
        "    if len(result) == n:\n",
        "        yield result    \n",
        "    for elem in it:\n",
        "        result = result[1:] + (elem,)\n",
        "        yield result\n",
        "\n",
        "# isa o Counter para contar a frequencia de unigramas e bigramas\n",
        "def ngrams(Words):\n",
        "    \"Retarna a contagem de unigramas e bigramas a partir da lista de palavras\"\n",
        "  \n",
        "    # Conta Unigramas (utilizando o counter de collections)\n",
        "    Unigrams = Counter(Words)\n",
        "\n",
        "    # windows retora uma janela delizante de tamanho 2\n",
        "    Bigrams  = Counter(window(Words,2))\n",
        "\n",
        "    return(Unigrams,Bigrams)\n",
        "\n",
        "# funcao auxiliar para calcular as probabilidades\n",
        "BigramProbabilities = lambda w1, w2 : bigrams [ (w1,w2) ] / unigrams[ w1 ]\n",
        "\n",
        "# aplica o score em uma lista de sentencas\n",
        "def score(phrases):\n",
        "\n",
        "    # loop sobre todas as sentencas de teste\n",
        "    for phrase in phrases:\n",
        "        Words = re.findall(regex, phrase)\n",
        "        P = float(1.0)\n",
        "        for w_0, w_1 in window(Words,2):\n",
        "            P = P * BigramProbabilities(w_0, w_1)\n",
        "\n",
        "        print ( \"{1:.20f} : Sentença: {0}\".format( phrase, P ) ) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI3YD1xOTl8a"
      },
      "source": [
        "### **Testando o Modelo**\n",
        "\n",
        "Cria uma sequência de sentenças e um modelo de bigramas baseado no livro de **Machado de Assis**, e aplica a função score na lista de sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVj8TEvcwXE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77b8eb9d-57ae-4733-e6b0-b467e0b98669"
      },
      "source": [
        "sentencas = [\"ele é\",\n",
        "             \"ele é uma\", \n",
        "             \"ele é uma pessoa\", \n",
        "             \"ele é uma pessoa de\", \n",
        "             \"ele é uma pessoa de verdade\"]\n",
        "\n",
        "words = get_tokens(\"/content/A-Semana-Machado-de-Assis.txt\")\n",
        "\n",
        "unigrams, bigrams = ngrams(words)\n",
        "score(sentencas)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.02647657841140529586 : Sentença: ele é\n",
            "0.00069189664838167149 : Sentença: ele é uma\n",
            "0.00000842133213707000 : Sentença: ele é uma pessoa\n",
            "0.00000050654629395910 : Sentença: ele é uma pessoa de\n",
            "0.00000000051863038186 : Sentença: ele é uma pessoa de verdade\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbNTzxnmT_na"
      },
      "source": [
        "Repetimos o processo, agora considerando todas as obras de Machado de Assis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8OnobVXCM3D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d6ad5a0-dcf1-42cb-c89e-57131df6bfd7"
      },
      "source": [
        "sentencas = [\"ele é\",\n",
        "             \"ele é uma\", \n",
        "             \"ele é uma pessoa\", \n",
        "             \"ele é uma pessoa de\", \n",
        "             \"ele é uma pessoa de verdade\"]\n",
        "\n",
        "words = get_tokens(\"/content/Todas-as-obras-Machado-de-Assis.txt\")\n",
        "\n",
        "unigrams, bigrams = ngrams(words)\n",
        "score(sentencas)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.02488038277511961729 : Sentença: ele é\n",
            "0.00093406050182903407 : Sentença: ele é uma\n",
            "0.00000825483405278844 : Sentença: ele é uma pessoa\n",
            "0.00000046590235609081 : Sentença: ele é uma pessoa de\n",
            "0.00000000050723310908 : Sentença: ele é uma pessoa de verdade\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f4on2F4FSfl",
        "outputId": "820d8cf2-09d1-407e-833e-bfbc5838d105"
      },
      "source": [
        "print(len(words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1535663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0_OnhUnE-Qs",
        "outputId": "04f5daf7-7813-44db-943d-add718339625"
      },
      "source": [
        "print(len(unigrams))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjXwxoRlFGl4",
        "outputId": "e93a34ed-323e-4123-931e-3b5b443ca871"
      },
      "source": [
        "print(len(bigrams))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "618262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orahrwRdUHpn"
      },
      "source": [
        "### **Probabilidade da próxima palavra**\n",
        "\n",
        "Usamos o modelo de bigrama para calcular quais as palavras mais prováveis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGwISM_1EiHy"
      },
      "source": [
        "def next_prob(phrase,n=5):\n",
        "    # quebre a sentenca em palavras\n",
        "    Words = re.findall(regex, phrase)\n",
        "\n",
        "    # calcula as probabilidades de todas as palavras em que o bigrama eh w1 e armazena em prob\n",
        "    probs = {w2 : BigramProbabilities(w1,w2) for (w1,w2) in bigrams.keys() if w1 == Words[-1] }\n",
        "\n",
        "    # ordena e imprime as n mais relevantes\n",
        "    for w, p in islice(sorted(probs.items(), key = lambda item: item[1], reverse=True),n):\n",
        "        print ( \"{0} -> {1} ({2:.2f}%)\".format( phrase, w.upper(), p*100 ) )   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55a4_4VWUbvC"
      },
      "source": [
        "**Teste da função `next_prob`**\n",
        "\n",
        "O usuário digita frases e são listadas as 5 palavras mais prováveis de acordo com o modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltyUH_zcLLL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a51c3e3-5f14-4baa-d384-38bbec6f8cf8"
      },
      "source": [
        "words = get_tokens(\"/content/A-Semana-Machado-de-Assis.txt\")\n",
        "#words = get_tokens(\"/content/Todas-as-obras-Machado-de-Assis.txt\")\n",
        "\n",
        "unigrams, bigrams = ngrams(words)\n",
        "\n",
        "phrase = input(\"\\nDigite uma frase: \")\n",
        "\n",
        "while (phrase != \"\"):\n",
        "    next_prob(phrase)\n",
        "    phrase = input(\"\\nDigite uma frase:\")\n",
        "\n",
        "# frase: ele é uma pessoa\n",
        "# frase: estudar\n",
        "# frase: a semana que"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Digite uma frase: ele é uma pessoa\n",
            "ele é uma pessoa -> QUE (28.57%)\n",
            "ele é uma pessoa -> DE (6.02%)\n",
            "ele é uma pessoa -> A (4.51%)\n",
            "ele é uma pessoa -> É (2.26%)\n",
            "ele é uma pessoa -> NO (2.26%)\n",
            "\n",
            "Digite uma frase:estudar\n",
            "estudar -> A (30.00%)\n",
            "estudar -> O (30.00%)\n",
            "estudar -> E (10.00%)\n",
            "estudar -> ESSA (10.00%)\n",
            "estudar -> AS (10.00%)\n",
            "\n",
            "Digite uma frase:a semana que\n",
            "a semana que -> O (7.33%)\n",
            "a semana que -> A (6.90%)\n",
            "a semana que -> NÃO (5.89%)\n",
            "a semana que -> SE (4.82%)\n",
            "a semana que -> É (3.59%)\n",
            "\n",
            "Digite uma frase:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvF9UFUYU481"
      },
      "source": [
        "**Teste da função `next_prob`**\n",
        "\n",
        "O usuário digita frases e são listadas as 5 palavras mais prováveis de acordo com o modelo, **sem considerar as *stopwords***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEzurfRyikTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98c6724d-abc5-4aa4-c071-0752bad34a59"
      },
      "source": [
        "words = get_tokens_without_stopwords(\"/content/A-Semana-Machado-de-Assis.txt\")\n",
        "#words = get_tokens_without_stopwords(\"/content/Todas-as-obras-Machado-de-Assis.txt\")\n",
        "\n",
        "unigrams, bigrams = ngrams(words)\n",
        "\n",
        "phrase = input(\"\\nDigite uma frase: \")\n",
        "\n",
        "while (phrase != \"\"):\n",
        "    next_prob(phrase)\n",
        "    phrase = input(\"\\nDigite uma frase:\")\n",
        "\n",
        "# frase: que\n",
        "# frase: rio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Digite uma frase: que\n",
            "\n",
            "Digite uma frase:rio\n",
            "rio -> JANEIRO (54.70%)\n",
            "rio -> GRANDE (15.38%)\n",
            "rio -> BRANCO (5.98%)\n",
            "rio -> CLARO (2.56%)\n",
            "rio -> NEWS (1.71%)\n",
            "\n",
            "Digite uma frase:\n"
          ]
        }
      ]
    }
  ]
}