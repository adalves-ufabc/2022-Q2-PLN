{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2022-Q2 PLN Notebook 20.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNgJFKqXGsA918fcT2HUCDa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalves-ufabc/2022.Q2-PLN/blob/main/2022_Q2_PLN_Notebook_20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk8y4Xyp9eRD"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2022.Q2]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q9RGmcs9iAe"
      },
      "source": [
        "### **Modelagem de Tópicos com LDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEN81Am69mp0"
      },
      "source": [
        "Neste exemplo faremos a modelagem de tópicos no texto obtido de artigos da Wikipedia. Para baixar a biblioteca `wikipedia`, execute o seguinte comando:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIU0fm91XJ6i",
        "outputId": "2b2d1faa-4b6a-4d67-c140-127d364db2a4"
      },
      "source": [
        "!pip install wikipedia"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (4.6.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11695 sha256=86bacdc6a1fa2be6ad4951ecbd2ba64cdc808c48a19f4f73354243aba7836bec\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/93/6d/5b2c68b8a64c7a7a04947b4ed6d89fb557dcc6bc27d1d7f3ba\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0geNTLJ-HEO"
      },
      "source": [
        "Para visualizar nosso modelo de tópicos, usaremos a biblioteca `pyLDAvis`. Para fazer o download da biblioteca, execute o seguinte comando `pip`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTuYNgZ3XOfQ",
        "outputId": "fd99d549-4d33-40c0-f28b-f924af34546f"
      },
      "source": [
        "!pip install pyLDAvis==2.1.2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyLDAvis==2.1.2\n",
            "  Downloading pyLDAvis-2.1.2.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (0.37.1)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (1.7.3)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (1.3.5)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (1.1.0)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (2.11.3)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (2.8.3)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (3.6.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (0.16.0)\n",
            "Collecting funcy\n",
            "  Downloading funcy-1.17-py2.py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.7.2->pyLDAvis==2.1.2) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->pyLDAvis==2.1.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->pyLDAvis==2.1.2) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.17.0->pyLDAvis==2.1.2) (1.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from numexpr->pyLDAvis==2.1.2) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->numexpr->pyLDAvis==2.1.2) (3.0.9)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (1.11.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (8.13.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (22.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (57.4.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (1.4.1)\n",
            "Building wheels for collected packages: pyLDAvis\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97738 sha256=1ce3729541e9548c814eb82dcc52afa63f1a4fcada7346eb156deaf6ca5cc54d\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/fb/41/e32e5312da9f440d34c4eff0d2207b46dc9332a7b931ef1e89\n",
            "Successfully built pyLDAvis\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-1.17 pyLDAvis-2.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeiro importamos as bibliotecas `wikipedia` e `nltk`. Também baixamos as *stop words* em inglês. \n"
      ],
      "metadata": {
        "id": "jET8GoH0l02a"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMHkBLFlXVeo",
        "outputId": "df7dfafa-a404-491c-c80e-df67d5ea591c"
      },
      "source": [
        "import wikipedia\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "en_stop = set(nltk.corpus.stopwords.words('english'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4u-i7QR-qPX"
      },
      "source": [
        "Em seguida, baixamos o artigo da Wikipedia especificando o tópico para o objeto `page` da biblioteca `wikipedia`. O objeto retornado contém informações sobre a página baixada.\n",
        "\n",
        ">\n",
        "Para recuperar o conteúdo da página Web, podemos usar o atributo `content`. O conteúdo de todos os quatro artigos é armazenado na lista denominada `corpus`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "covid = wikipedia.page(\"covid\")\n",
        "artificial_intelligence = wikipedia.page(\"Artificial Intelligence\")\n",
        "leonardo_vinci = wikipedia.page(\"Leonardo da Vinci\")\n",
        "eiffel_tower = wikipedia.page(\"Eiffel Tower\")\n",
        "\n",
        "corpus = [covid.content, artificial_intelligence.content, leonardo_vinci.content, eiffel_tower.content]"
      ],
      "metadata": {
        "id": "591d4-vYlUKM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VutL6XK9_ju8"
      },
      "source": [
        "**Pré-processamento dos dados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87WuHpKU_ncd"
      },
      "source": [
        "Para realizar a modelagem de tópicos via LDA, precisamos de um dicionário de dados e da sacola de palavras (*bag of words*) do corpus. Para isso, precisamos de dados na forma de tokens.\n",
        "\n",
        ">\n",
        "Além disso, precisamos remover pontuações e *stop words* de nosso conjunto de dados. Por uma questão de uniformidade, converteremos todos os tokens para minúsculas e também os lematizaremos. Além disso, removeremos todos os tokens com menos de 5 caracteres."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "359RX4uaXynQ"
      },
      "source": [
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "stemmer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(document):\n",
        "        # remove all the special characters\n",
        "        document = re.sub(r'\\W', ' ', str(document))\n",
        "\n",
        "        # remove all single characters\n",
        "        document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
        "\n",
        "        # remove single characters from the start\n",
        "        document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document)\n",
        "\n",
        "        # substituting multiple spaces with single space\n",
        "        document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
        "\n",
        "        # removing prefixed 'b'\n",
        "        document = re.sub(r'^b\\s+', '', document)\n",
        "\n",
        "        # converting to lowercase\n",
        "        document = document.lower()\n",
        "\n",
        "        # lemmatization\n",
        "        tokens = document.split()\n",
        "        tokens = [stemmer.lemmatize(word) for word in tokens]\n",
        "        tokens = [word for word in tokens if word not in en_stop]\n",
        "        tokens = [word for word in tokens if len(word)  > 5]\n",
        "\n",
        "        return tokens"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q0sy0gqYa8y",
        "outputId": "36b6a435-e32b-4830-d0fd-93b40ed4f339"
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTYjeuKGYSbO"
      },
      "source": [
        "processed_data = [];\n",
        "for doc in corpus:\n",
        "    tokens = preprocess_text(doc)\n",
        "    processed_data.append(tokens)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBG4PAmDA7NB"
      },
      "source": [
        "No trecho de código acima nós iteramos através da lista de `corpus` que contém os quatro artigos da Wikipedia na forma de strings. Em cada iteração, passamos o documento para o método `preprocess_text` que criamos anteriormente. O método retorna tokens para esse documento específico. Os tokens são armazenados na lista `processed_data`.\n",
        "\n",
        ">\n",
        "No final do loop `for`, todos os tokens dos quatro artigos serão armazenados na lista `processed_data`. Agora podemos usar essa lista para criar um dicionário e a sacola de palavras correspondente ao corpus. O seguinte *script* faz isso:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP99ajZTYhQn"
      },
      "source": [
        "from gensim import corpora\n",
        "\n",
        "gensim_dictionary = corpora.Dictionary(processed_data)\n",
        "gensim_corpus = [gensim_dictionary.doc2bow(token, allow_update=True) for token in processed_data]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtBrjJqPB9GX"
      },
      "source": [
        "A seguir, salvaremos nosso dicionário, bem como a sacola de palavras do corpus usando `pickle`. Usaremos o dicionário salvo mais tarde para fazer previsões sobre os novos dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g87fTizNYic1"
      },
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump(gensim_corpus, open('gensim_corpus_corpus.pkl', 'wb'))\n",
        "gensim_dictionary.save('gensim_dictionary.gensim')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pj2nlTBCZYB"
      },
      "source": [
        "Agora, temos tudo o que é necessário para criar o **modelo LDA** no `Gensim`. Usaremos a classe `LdaModel` do módulo `gensim.models.ldamodel` para criar o modelo LDA. Precisamos passar a sacola de palavras do corpus que criamos anteriormente como o primeiro parâmetro para o construtor `LdaModel`, seguido pelo número de tópicos, o dicionário que criamos anteriormente e o número de passagens (número de iterações para o modelo)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pCEwsaOYmG3"
      },
      "source": [
        "import gensim\n",
        "\n",
        "lda_model = gensim.models.ldamodel.LdaModel(gensim_corpus, num_topics=4, id2word=gensim_dictionary, passes=20)\n",
        "lda_model.save('gensim_model.gensim')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kH2j-XqDlY1"
      },
      "source": [
        "Sim, é assim tão simples. No script acima, criamos o modelo LDA de nosso conjunto de dados e o salvamos.\n",
        "\n",
        ">\n",
        "A seguir, vamos imprimir 10 palavras para cada tópico. Para fazer isso, podemos usar o método `print_topics`. Execute o seguinte *script*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMwTh6ZqYqUV",
        "outputId": "b0a02c9a-1897-4b4b-8eaa-d31f7f39c0cc"
      },
      "source": [
        "topics = lda_model.print_topics(num_words=10)\n",
        "for topic in topics:\n",
        "    print(topic)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.049*\"leonardo\" + 0.014*\"painting\" + 0.008*\"drawing\" + 0.004*\"florence\" + 0.004*\"vasari\" + 0.004*\"artist\" + 0.004*\"verrocchio\" + 0.003*\"painter\" + 0.003*\"including\" + 0.003*\"century\"')\n",
            "(1, '0.019*\"corvus\" + 0.018*\"corvids\" + 0.013*\"specie\" + 0.012*\"magpie\" + 0.006*\"social\" + 0.006*\"corvid\" + 0.006*\"family\" + 0.006*\"cyanocorax\" + 0.005*\"corvidae\" + 0.004*\"ability\"')\n",
            "(2, '0.019*\"intelligence\" + 0.015*\"artificial\" + 0.010*\"machine\" + 0.009*\"learning\" + 0.009*\"problem\" + 0.007*\"research\" + 0.007*\"network\" + 0.006*\"system\" + 0.006*\"algorithm\" + 0.005*\"search\"')\n",
            "(3, '0.025*\"eiffel\" + 0.007*\"second\" + 0.006*\"french\" + 0.005*\"exposition\" + 0.005*\"structure\" + 0.005*\"france\" + 0.005*\"tallest\" + 0.005*\"engineer\" + 0.004*\"design\" + 0.004*\"construction\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7aSkuP6DziY"
      },
      "source": [
        "**IMPORTANTE**: A ordem dos tópicos pode mudar a cada execução do código.\n",
        ">\n",
        "O tópico 2 contém palavras como *intelligence*, *artificial*, *machine* etc. Podemos supor que essas palavras pertencem ao tópico relacionado a Inteligência Artificial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3491PqsqGKvb"
      },
      "source": [
        "Podemos ver claramente que o modelo LDA identificou com sucesso os quatro tópicos em nosso conjunto de dados.\n",
        "\n",
        ">\n",
        "É importante mencionar aqui que o LDA é um algoritmo de aprendizado não supervisionado e, em problemas do mundo real, você não saberá sobre os tópicos do conjunto de dados de antemão. Você simplesmente receberá um corpus, os tópicos serão criados usando LDA e, em seguida, os nomes dos tópicos dependem de você."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbkZqLLPGWVe"
      },
      "source": [
        "Vamos agora criar 8 tópicos usando nosso conjunto de dados. Iremos imprimir 5 palavras por tópico:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpuE2OUhYuLW",
        "outputId": "0cf218c8-7172-44f2-b5dc-1e3978a4dd50"
      },
      "source": [
        "lda_model = gensim.models.ldamodel.LdaModel(gensim_corpus, num_topics=8, id2word=gensim_dictionary, passes=15)\n",
        "lda_model.save('gensim_model.gensim')\n",
        "topics = lda_model.print_topics(num_words=5)\n",
        "for topic in topics:\n",
        "    print(topic)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.000*\"eiffel\" + 0.000*\"leonardo\" + 0.000*\"second\" + 0.000*\"painting\" + 0.000*\"french\"')\n",
            "(1, '0.000*\"intelligence\" + 0.000*\"artificial\" + 0.000*\"machine\" + 0.000*\"leonardo\" + 0.000*\"research\"')\n",
            "(2, '0.000*\"leonardo\" + 0.000*\"corvids\" + 0.000*\"intelligence\" + 0.000*\"painting\" + 0.000*\"artificial\"')\n",
            "(3, '0.000*\"leonardo\" + 0.000*\"intelligence\" + 0.000*\"painting\" + 0.000*\"drawing\" + 0.000*\"machine\"')\n",
            "(4, '0.056*\"leonardo\" + 0.016*\"painting\" + 0.009*\"drawing\" + 0.005*\"florence\" + 0.005*\"vasari\"')\n",
            "(5, '0.013*\"intelligence\" + 0.009*\"artificial\" + 0.008*\"eiffel\" + 0.007*\"corvus\" + 0.006*\"machine\"')\n",
            "(6, '0.000*\"intelligence\" + 0.000*\"leonardo\" + 0.000*\"artificial\" + 0.000*\"problem\" + 0.000*\"machine\"')\n",
            "(7, '0.000*\"leonardo\" + 0.000*\"eiffel\" + 0.000*\"intelligence\" + 0.000*\"artificial\" + 0.000*\"corvids\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhVl-zxdGiE8"
      },
      "source": [
        "Novamente, o número de tópicos que deseja criar depende de você. Continue tentando números diferentes até encontrar tópicos adequados. Para nosso conjunto de dados, o número adequado de tópicos é 4, pois já sabemos que nosso corpus contém palavras de quatro artigos diferentes. Reverta para quatro tópicos executando o seguinte *script*:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnZMap1RGwAV"
      },
      "source": [
        "Desta vez, você verá resultados diferentes, uma vez que os valores iniciais para os parâmetros LDA são escolhidos aleatoriamente. Os resultados desta vez são os seguintes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVqr-iLiY0XF",
        "outputId": "4db9ba1d-8356-49a9-85db-b0c9a338a76e"
      },
      "source": [
        "lda_model = gensim.models.ldamodel.LdaModel(gensim_corpus, num_topics=4, id2word=gensim_dictionary, passes=20)\n",
        "lda_model.save('gensim_model.gensim')\n",
        "topics = lda_model.print_topics(num_words=10)\n",
        "for topic in topics:\n",
        "    print(topic)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.019*\"intelligence\" + 0.015*\"artificial\" + 0.010*\"machine\" + 0.009*\"learning\" + 0.009*\"problem\" + 0.007*\"research\" + 0.007*\"network\" + 0.006*\"system\" + 0.006*\"algorithm\" + 0.005*\"search\"')\n",
            "(1, '0.049*\"leonardo\" + 0.014*\"painting\" + 0.008*\"drawing\" + 0.004*\"florence\" + 0.004*\"vasari\" + 0.004*\"artist\" + 0.004*\"verrocchio\" + 0.003*\"painter\" + 0.003*\"including\" + 0.003*\"century\"')\n",
            "(2, '0.025*\"eiffel\" + 0.007*\"second\" + 0.006*\"french\" + 0.005*\"structure\" + 0.005*\"exposition\" + 0.005*\"france\" + 0.005*\"tallest\" + 0.005*\"engineer\" + 0.004*\"design\" + 0.004*\"construction\"')\n",
            "(3, '0.019*\"corvus\" + 0.018*\"corvids\" + 0.013*\"specie\" + 0.012*\"magpie\" + 0.006*\"social\" + 0.006*\"corvid\" + 0.006*\"family\" + 0.006*\"cyanocorax\" + 0.005*\"corvidae\" + 0.004*\"ability\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-VkZZJ-G7Nn"
      },
      "source": [
        "**Avaliando o modelo LDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-ObCg3AG97W"
      },
      "source": [
        "Conforme mencionado anteriormente, os modelos de aprendizagem não supervisionados são difíceis de avaliar, uma vez que não existe uma verdade concreta contra a qual possamos testar a saída de nosso modelo.\n",
        "\n",
        ">\n",
        "Suponha que temos um novo documento de texto e queremos encontrar seu tópico usando o modelo LDA que acabamos de criar, podemos fazer isso usando o seguinte *script*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sYxh1avY4Ou",
        "outputId": "c4e57d41-b3b3-4764-c942-59b0e05ab44e"
      },
      "source": [
        "test_doc = 'Great structures are build to remember an event happened in the history.'\n",
        "test_doc = preprocess_text(test_doc)\n",
        "bow_test_doc = gensim_dictionary.doc2bow(test_doc)\n",
        "\n",
        "print(lda_model.get_document_topics(bow_test_doc))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 0.06355073), (1, 0.0635583), (2, 0.51557046), (3, 0.35732052)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwnMao7jHe_2"
      },
      "source": [
        "No *script* acima, criamos uma string, criamos sua representação no dicionário e então convertemos a string no corpus do saco de palavras. A representação do saco de palavras é então passada para o método `get_document_topics`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1RGmeF8H03w"
      },
      "source": [
        "A saída mostra que há 51,55% de chance de que o novo documento pertença ao  tópico 2 (consulte as palavras para o tópico 2 na última saída). Da mesma forma, há 35,73% de chance de este documento pertencer ao tópico 3 (covid). Se olharmos para o tópico 2, ele contém palavras relacionadas à Torre Eiffel. Nosso documento de teste também contém palavras relacionadas a estruturas e edifícios. Portanto, foi atribuído o tópico 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaEFKliXIgps"
      },
      "source": [
        "Outra forma de avaliar o modelo LDA é por meio de `Perplexity` (Perplexidade) e `Coherence Score` (Coerência)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPD0j72sIs5V"
      },
      "source": [
        "Como regra geral para um bom modelo de LDA, a pontuação de perplexidade deve ser baixa, enquanto a coerência deve ser alta. A biblioteca Gensim possui uma classe `CoherenceModel` que pode ser usada para encontrar a coerência do modelo LDA. Para perplexidade, o objeto `LdaModel` contém o método `log_perplexity` que pega uma sacola de palavras como parâmetro e retorna a perplexidade correspondente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri16KbcbY_OG",
        "outputId": "0cc87a61-307d-42da-d302-c348edbc9e8e"
      },
      "source": [
        "print('\\nPerplexity:', lda_model.log_perplexity(gensim_corpus))\n",
        "\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "coherence_score_lda = CoherenceModel(model=lda_model, texts=processed_data, dictionary=gensim_dictionary, coherence='c_v')\n",
        "coherence_score = coherence_score_lda.get_coherence()\n",
        "\n",
        "print('\\nCoherence Score:', coherence_score)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Perplexity: -7.736988352824177\n",
            "\n",
            "Coherence Score: 0.6435901836032951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AShpPJi2JRdE"
      },
      "source": [
        "**Visualizando o modelo LDA**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "CQkCRj5cr1Ec"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqZSVQBxJjSk"
      },
      "source": [
        "Para visualizar nossos dados, podemos usar a biblioteca `pyLDAvis` que baixamos no início."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy8MKyyeZDCz"
      },
      "source": [
        "gensim_dictionary = gensim.corpora.Dictionary.load('gensim_dictionary.gensim')\n",
        "gensim_corpus = pickle.load(open('gensim_corpus_corpus.pkl', 'rb'))\n",
        "lda_model = gensim.models.ldamodel.LdaModel.load('gensim_model.gensim')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis.gensim\n",
        "\n",
        "lda_visualization = pyLDAvis.gensim.prepare(lda_model, gensim_corpus, gensim_dictionary, sort_topics=False)\n",
        "pyLDAvis.display(lda_visualization)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 954
        },
        "id": "x7aHS8iZprdm",
        "outputId": "acf37269-bc74-4e03-98af-a8f7aa97c4d8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n",
            "/usr/local/lib/python3.7/dist-packages/pyLDAvis/_prepare.py:232: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  head(R).drop('saliency', 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el591401758885387043567194330\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el591401758885387043567194330_data = {\"mdsDat\": {\"x\": [-0.13476520080826235, 0.1328398960143509, 0.07561328491437382, -0.07368798012046215], \"y\": [0.11576919795304576, 0.027714990019551394, 0.009021643762214983, -0.15250583173481216], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [37.83561747311634, 27.080527553651535, 17.617437085079874, 17.466417888152243]}, \"tinfo\": {\"Term\": [\"leonardo\", \"eiffel\", \"corvus\", \"corvids\", \"intelligence\", \"artificial\", \"painting\", \"specie\", \"magpie\", \"learning\", \"drawing\", \"machine\", \"network\", \"problem\", \"second\", \"algorithm\", \"social\", \"corvid\", \"research\", \"cyanocorax\", \"exposition\", \"family\", \"french\", \"florence\", \"structure\", \"tallest\", \"vasari\", \"corvidae\", \"france\", \"engineer\", \"network\", \"artificial\", \"algorithm\", \"neural\", \"program\", \"application\", \"technology\", \"language\", \"diplomacy\", \"decision\", \"neuron\", \"computing\", \"cybersecurity\", \"security\", \"optimization\", \"russia\", \"classifier\", \"question\", \"future\", \"solution\", \"software\", \"learning\", \"problem\", \"computer\", \"market\", \"solving\", \"google\", \"turing\", \"robotics\", \"symbolic\", \"intelligence\", \"research\", \"reasoning\", \"search\", \"process\", \"machine\", \"knowledge\", \"approach\", \"system\", \"intelligent\", \"information\", \"researcher\", \"general\", \"example\", \"however\", \"scientific\", \"leonardo\", \"florence\", \"vasari\", \"painting\", \"verrocchio\", \"anatomy\", \"ludovico\", \"medici\", \"virgin\", \"composition\", \"portrait\", \"notebook\", \"remains\", \"francis\", \"treatise\", \"sforza\", \"historian\", \"lifetime\", \"renaissance\", \"amboise\", \"lorenzo\", \"painter\", \"michelangelo\", \"quality\", \"supper\", \"christ\", \"genius\", \"venice\", \"caterina\", \"manuscript\", \"drawing\", \"brother\", \"journal\", \"artist\", \"battle\", \"figure\", \"workshop\", \"interest\", \"writing\", \"landscape\", \"subject\", \"century\", \"including\", \"famous\", \"received\", \"considered\", \"france\", \"machine\", \"although\", \"created\", \"eiffel\", \"exposition\", \"tallest\", \"restaurant\", \"installed\", \"minute\", \"replaced\", \"gustave\", \"aerial\", \"pillar\", \"transmitter\", \"protest\", \"construction\", \"contract\", \"apartment\", \"ascent\", \"passenger\", \"mounted\", \"fitted\", \"edison\", \"visitor\", \"hydraulic\", \"height\", \"exploitation\", \"bottom\", \"chrysler\", \"diameter\", \"maintenance\", \"lattice\", \"soci\\u00e9t\\u00e9\", \"second\", \"building\", \"structure\", \"original\", \"french\", \"monument\", \"million\", \"engineer\", \"copyright\", \"france\", \"structural\", \"design\", \"completed\", \"television\", \"public\", \"company\", \"drawing\", \"system\", \"various\", \"government\", \"corvus\", \"corvids\", \"specie\", \"magpie\", \"corvid\", \"cyanocorax\", \"corvidae\", \"billed\", \"cyanolyca\", \"jackdaw\", \"treepie\", \"breeding\", \"carrion\", \"aphelocoma\", \"dendrocitta\", \"lineage\", \"nutcracker\", \"passerine\", \"eurasian\", \"throated\", \"urocissa\", \"podoces\", \"mammal\", \"context\", \"holarctic\", \"collared\", \"habitat\", \"caledonian\", \"perisoreus\", \"garrulus\", \"nucifraga\", \"social\", \"family\", \"personality\", \"american\", \"territory\", \"emotional\", \"member\", \"emotion\", \"ability\", \"common\", \"animal\", \"however\", \"environment\", \"related\", \"intelligence\", \"including\"], \"Freq\": [158.0, 52.0, 40.0, 37.0, 95.0, 67.0, 46.0, 27.0, 24.0, 43.0, 31.0, 54.0, 29.0, 41.0, 19.0, 26.0, 17.0, 13.0, 34.0, 12.0, 12.0, 17.0, 16.0, 15.0, 15.0, 10.0, 14.0, 10.0, 18.0, 14.0, 29.389877249607423, 66.68484325669046, 26.14652325927584, 17.229032922274023, 17.228647547501236, 17.228146665303363, 14.796037023643727, 13.17482520838078, 12.364308556486874, 12.364219300749307, 10.742610559971066, 10.742538105313512, 10.742380595188395, 10.742322841475852, 10.742178982228246, 9.93177153735442, 9.121139378035426, 9.120748752925136, 9.120558690707496, 8.310443689632637, 8.310278304001264, 40.74156896273043, 39.12042855205753, 16.41737904727677, 6.688857000271913, 6.688723116665563, 6.68870526551805, 6.688611809510481, 6.688587132924212, 15.606597778372667, 87.77114373308659, 31.823776206288386, 13.985728285114973, 20.472622127725778, 13.175260986393603, 45.60636368304013, 18.850129230111882, 18.8500158228218, 27.768921650814665, 18.850456851172126, 15.60689914774539, 18.03917470007015, 18.040042055825793, 18.850622761837247, 10.743942045562054, 10.743696329766872, 157.7804467234601, 14.515395523529936, 13.761078220351614, 44.677374671345895, 11.499273217399896, 9.990732558174907, 8.48291792238335, 8.482817962635268, 8.482849528871505, 8.482602260020988, 7.728893734255792, 7.728841875439119, 6.974932678600708, 6.974792885268805, 6.9747710895342605, 6.974607245736654, 6.220967113483303, 6.220849115885944, 6.220755168754288, 5.4668256793354395, 5.46673774482021, 10.745370784754963, 4.712805624881676, 4.712783453358605, 4.712716938789392, 4.712600068557613, 9.236904531658245, 3.958825779800259, 3.958787073582017, 3.9587164253390124, 26.579588626691116, 6.975035644657002, 6.22118657398285, 13.007429820750676, 6.2207641876789275, 9.237844754551851, 6.220965610329197, 8.482684933496845, 6.975062701430918, 6.975144623329722, 7.7296746228141116, 9.992142516726789, 9.99267839116575, 6.975196482146395, 6.975616613719158, 7.72970919535856, 7.730941030148824, 8.48506668117857, 6.975843589989237, 6.975590308522294, 52.116759951380565, 11.488980207630267, 10.156778939449753, 8.158736177498707, 6.160772624475576, 4.829046609862556, 4.8288172951268, 4.828818273014799, 4.162831562876422, 4.162815916668438, 4.1626545651486095, 4.162667277692596, 8.824841701028959, 3.4967130823301837, 3.496683745690215, 3.4966744557542246, 3.496659054018241, 3.4966416965062597, 3.4966030699303006, 3.496549286090358, 7.493082438223974, 7.492908374160159, 6.827041455301654, 2.830842985335681, 2.830724905359807, 2.8307019249918315, 2.830668432327867, 2.8306823672318524, 2.830673321767862, 2.830663298415873, 15.485785457099592, 7.493146000943906, 11.489794788333398, 7.493121553743932, 12.15606899754347, 6.8271040401335865, 8.159235389322175, 9.491794564510306, 4.828855921702759, 10.157912311640544, 4.162874589948375, 8.825670950052075, 6.161213651963106, 4.162937174780309, 6.827251701221429, 7.492988072032074, 4.166020455641023, 4.163651521963548, 4.163242764779983, 4.1630672338841705, 40.00954120702602, 36.68904337273372, 27.391277146640626, 24.07134938152518, 12.783106155508582, 11.454959375083416, 9.46227675036853, 7.470626648907631, 6.806667660332579, 6.806605611986799, 6.80651932600595, 6.806471335488511, 6.806359842367188, 6.142212769743992, 5.478140833789513, 4.814372353026113, 4.814294792593889, 4.150357133137699, 4.150347922836372, 4.15030235608244, 4.1501850459287, 3.4862820462906607, 3.4862704122258275, 2.822299789585942, 2.822280884230587, 2.8222946996825775, 2.8222813689832886, 2.8222777333380282, 2.8222668264022466, 2.822262948380635, 2.8222644026387393, 13.4473986539422, 12.119089966114764, 4.814294792593889, 8.135314705545595, 4.150448266645562, 4.15033677352424, 7.471095404769889, 6.142938929290694, 8.135507637120753, 5.478613467673382, 6.1428763961922135, 5.480202487028584, 4.81490994377197, 4.815268660771009, 6.149856835092429, 4.816869314191044], \"Total\": [158.0, 52.0, 40.0, 37.0, 95.0, 67.0, 46.0, 27.0, 24.0, 43.0, 31.0, 54.0, 29.0, 41.0, 19.0, 26.0, 17.0, 13.0, 34.0, 12.0, 12.0, 17.0, 16.0, 15.0, 15.0, 10.0, 14.0, 10.0, 18.0, 14.0, 29.91740843337287, 67.88458443055728, 26.673718329447176, 17.753575938721582, 17.75349484256813, 17.75341701727153, 15.320666947730924, 13.698823825436504, 12.887969080919571, 12.88794680711902, 11.266052143465767, 11.266065577857152, 11.266010520115216, 11.265995516568996, 11.26599778514581, 10.45509078012686, 9.644197163970997, 9.644139507256016, 9.644123804071217, 8.83326519505695, 8.833264025611799, 43.44342334751955, 41.73365056016644, 17.60879686830387, 7.211415913081099, 7.211388054117931, 7.211379881793448, 7.211365989425653, 7.2113655786392306, 16.885808382446207, 95.03811993596551, 34.43333278837454, 15.17604593277384, 22.415958777415153, 14.45315208751524, 54.43319154888253, 21.638176166848467, 21.638187687345, 35.974693836394394, 22.78679365989003, 18.214435407982446, 21.88580294385048, 22.159897162513364, 24.20733610239584, 21.596383059135746, 17.966754797581512, 158.37116692856375, 15.05555329669334, 14.30119369659142, 46.70452065196495, 12.038291300702008, 10.529727395321475, 9.021125541199115, 9.021115392015352, 9.021191334977608, 9.0211507108478, 8.266870196636793, 8.266876356656873, 7.512562271149726, 7.512563422277025, 7.512589545885852, 7.5125275285626, 6.7583203919981525, 6.7582956289291065, 6.758299418104082, 6.003983424393082, 6.003993220783509, 11.950261850868548, 5.249691756390001, 5.249692023479662, 5.249682261841033, 5.2497054825115494, 10.441627171715803, 4.495399149451367, 4.495409063388991, 4.495389863364411, 31.12183585541976, 8.17884005343872, 7.424565010131731, 16.878193187411917, 7.424530161384657, 12.585228861204742, 7.569235780102042, 11.453873788313182, 8.989767889093253, 9.134446132863653, 11.074636789283273, 20.055307969631347, 28.242309902850153, 9.511377704298084, 9.800732933173828, 16.457795796512507, 18.925161930170113, 54.43319154888253, 15.416182903017068, 11.27595554305617, 52.69258245353465, 12.050475898510266, 10.717979925404995, 8.719167907633635, 6.720324525601754, 5.387791885008922, 5.387802927267369, 5.387840230611106, 4.7215354699371685, 4.721543044668762, 4.721525329290617, 4.721560401652394, 10.049694702003581, 4.055274533098265, 4.055283360103765, 4.055286367715183, 4.05528450241411, 4.055284001590565, 4.055300538806886, 4.055289253563546, 8.807164521283728, 8.807147080336433, 8.140881991075428, 3.3889975507212573, 3.3890047943733745, 3.3890114242961045, 3.3890017632099108, 3.389021506046881, 3.3890126101751394, 3.3890213154534354, 19.178528941119392, 9.52806942913488, 15.180923645198511, 9.618111474676208, 16.54478101884356, 8.895200900611119, 10.948633977844262, 14.577403877512927, 6.198746445580994, 18.925161930170113, 5.385825780061186, 18.516731384075552, 10.548423738737512, 5.475824132113001, 12.893158536373043, 17.670906627847874, 31.12183585541976, 35.974693836394394, 12.424312943471673, 9.587109489717623, 40.58118430061025, 37.25973863791846, 27.95981863113727, 24.638284935744736, 13.345363606906046, 12.016834188599931, 10.024034764531416, 8.031126832531404, 7.366812795603044, 7.366792070212032, 7.3668266415375525, 7.366811216047283, 7.366852521709693, 6.702572537663946, 6.038240174339176, 5.373966719823725, 5.373972965487051, 4.709677510736075, 4.7096825782000975, 4.70968492837136, 4.709684181303846, 4.045380904288443, 4.045407431855662, 3.381081289436162, 3.3810789745370284, 3.3810959163350693, 3.381087847330711, 3.381084481418701, 3.381086384101631, 3.3810931567612537, 3.3810949464589317, 17.253404026396662, 17.206911130225457, 6.1282518738753655, 13.01368801762939, 5.520588345851124, 5.520623143772876, 14.229260981142094, 11.284893327830826, 19.12415788227213, 9.281997594747294, 12.209168868469394, 21.596383059135746, 11.71674856026845, 13.13728017206005, 95.03811993596551, 28.242309902850153], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.033400058746338, -4.214099884033203, -5.150300025939941, -5.567500114440918, -5.567500114440918, -5.567500114440918, -5.719699859619141, -5.835700035095215, -5.899199962615967, -5.899199962615967, -6.03980016708374, -6.03980016708374, -6.039899826049805, -6.039899826049805, -6.039899826049805, -6.118299961090088, -6.203499794006348, -6.203499794006348, -6.203499794006348, -6.296500205993652, -6.296599864959717, -4.7067999839782715, -4.747399806976318, -5.615699768066406, -6.513599872589111, -6.513599872589111, -6.513599872589111, -6.513599872589111, -6.513700008392334, -5.666399955749512, -3.939300060272217, -4.953800201416016, -5.776000022888184, -5.394999980926514, -5.835700035095215, -4.593999862670898, -5.477499961853027, -5.477499961853027, -5.090099811553955, -5.477499961853027, -5.666299819946289, -5.521500110626221, -5.521500110626221, -5.477499961853027, -6.039700031280518, -6.039700031280518, -3.018399953842163, -5.404399871826172, -5.457799911499023, -4.280200004577637, -5.63730001449585, -5.7779998779296875, -5.9415998458862305, -5.9415998458862305, -5.9415998458862305, -5.9415998458862305, -6.0346999168396, -6.0346999168396, -6.13730001449585, -6.13730001449585, -6.13730001449585, -6.13730001449585, -6.251699924468994, -6.251699924468994, -6.251699924468994, -6.380899906158447, -6.380899906158447, -5.705100059509277, -6.529300212860107, -6.529300212860107, -6.529399871826172, -6.529399871826172, -5.856400012969971, -6.703700065612793, -6.703700065612793, -6.703700065612793, -4.799499988555908, -6.13730001449585, -6.251699924468994, -5.514100074768066, -6.251699924468994, -5.856299877166748, -6.251699924468994, -5.9415998458862305, -6.13730001449585, -6.13730001449585, -6.034599781036377, -5.7778000831604, -5.7778000831604, -6.13730001449585, -6.137199878692627, -6.0345001220703125, -6.03439998626709, -5.941299915313721, -6.137199878692627, -6.137199878692627, -3.696199893951416, -5.2083001136779785, -5.331600189208984, -5.550600051879883, -5.831500053405762, -6.074999809265137, -6.075099945068359, -6.075099945068359, -6.223499774932861, -6.223499774932861, -6.223499774932861, -6.223499774932861, -5.472099781036377, -6.397900104522705, -6.397900104522705, -6.397900104522705, -6.397900104522705, -6.397900104522705, -6.397900104522705, -6.397900104522705, -5.635700225830078, -5.635700225830078, -5.728799819946289, -6.609099864959717, -6.6092000007629395, -6.6092000007629395, -6.6092000007629395, -6.6092000007629395, -6.6092000007629395, -6.6092000007629395, -4.909800052642822, -5.635700225830078, -5.208199977874756, -5.635700225830078, -5.151899814605713, -5.728799819946289, -5.55049991607666, -5.3993000984191895, -6.075099945068359, -5.331399917602539, -6.223499774932861, -5.4720001220703125, -5.831399917602539, -6.223499774932861, -5.728799819946289, -5.635700225830078, -6.222700119018555, -6.223299980163574, -6.223400115966797, -6.223400115966797, -3.9519999027252197, -4.038599967956543, -4.330900192260742, -4.460100173950195, -5.0929999351501465, -5.202700138092041, -5.393799781799316, -5.630099773406982, -5.723199844360352, -5.723199844360352, -5.723199844360352, -5.723199844360352, -5.723199844360352, -5.825900077819824, -5.940299987792969, -6.069499969482422, -6.069499969482422, -6.217899799346924, -6.217899799346924, -6.217899799346924, -6.217899799346924, -6.392199993133545, -6.392199993133545, -6.603499889373779, -6.603499889373779, -6.603499889373779, -6.603499889373779, -6.603499889373779, -6.603499889373779, -6.603499889373779, -6.603499889373779, -5.042300224304199, -5.146299839019775, -6.069499969482422, -5.544899940490723, -6.217899799346924, -6.217899799346924, -5.630000114440918, -5.825799942016602, -5.5447998046875, -5.940199851989746, -5.825799942016602, -5.939899921417236, -6.069399833679199, -6.069300174713135, -5.824699878692627, -6.068999767303467], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9541, 0.9541, 0.952, 0.9419, 0.9419, 0.9419, 0.9371, 0.9329, 0.9304, 0.9304, 0.9243, 0.9243, 0.9243, 0.9243, 0.9243, 0.9206, 0.9162, 0.9161, 0.9161, 0.9109, 0.9109, 0.9077, 0.9073, 0.9019, 0.8967, 0.8967, 0.8967, 0.8967, 0.8967, 0.8931, 0.8924, 0.8931, 0.8902, 0.8812, 0.8793, 0.795, 0.834, 0.834, 0.713, 0.7823, 0.8174, 0.7786, 0.7662, 0.7218, 0.2737, 0.4577, 1.3026, 1.2698, 1.2679, 1.262, 1.2605, 1.2538, 1.2448, 1.2448, 1.2448, 1.2448, 1.2391, 1.2391, 1.2321, 1.2321, 1.2321, 1.2321, 1.2235, 1.2235, 1.2235, 1.2126, 1.2126, 1.2001, 1.1985, 1.1985, 1.1985, 1.1984, 1.1838, 1.1792, 1.1792, 1.1792, 1.1486, 1.1471, 1.1295, 1.0459, 1.1295, 0.9971, 1.1102, 1.0061, 1.0526, 1.0367, 0.9468, 0.6097, 0.2674, 0.9962, 0.9663, 0.5506, 0.4111, -0.5523, 0.5134, 0.8261, 1.7253, 1.6886, 1.6825, 1.6698, 1.6493, 1.6268, 1.6267, 1.6267, 1.6103, 1.6103, 1.6103, 1.6103, 1.6063, 1.5881, 1.5881, 1.5881, 1.5881, 1.5881, 1.588, 1.588, 1.5747, 1.5747, 1.5603, 1.5563, 1.5563, 1.5563, 1.5563, 1.5563, 1.5563, 1.5563, 1.5224, 1.496, 1.4577, 1.4866, 1.428, 1.4717, 1.4422, 1.3072, 1.4865, 1.114, 1.4787, 0.9953, 1.1986, 1.4622, 1.1005, 0.8783, -0.2747, -0.4201, 0.6429, 0.9021, 1.7307, 1.7295, 1.7243, 1.7216, 1.7018, 1.697, 1.6872, 1.6725, 1.6658, 1.6658, 1.6658, 1.6658, 1.6658, 1.6576, 1.6475, 1.6349, 1.6349, 1.6185, 1.6185, 1.6185, 1.6184, 1.5962, 1.5961, 1.5642, 1.5642, 1.5642, 1.5642, 1.5642, 1.5642, 1.5642, 1.5642, 1.4957, 1.3944, 1.5036, 1.2751, 1.4596, 1.4596, 1.1006, 1.1367, 0.8902, 1.2177, 1.058, 0.3735, 0.8556, 0.7412, -0.993, -0.0238]}, \"token.table\": {\"Topic\": [1, 2, 4, 3, 1, 1, 2, 3, 4, 2, 1, 2, 3, 4, 2, 1, 2, 4, 3, 4, 1, 1, 2, 1, 4, 2, 3, 3, 2, 3, 4, 3, 4, 2, 3, 1, 3, 4, 4, 4, 2, 1, 2, 3, 4, 2, 3, 1, 4, 1, 4, 1, 2, 3, 1, 2, 3, 2, 1, 3, 1, 1, 2, 3, 4, 3, 4, 4, 3, 1, 3, 4, 4, 4, 4, 1, 2, 3, 4, 4, 4, 1, 1, 4, 1, 2, 3, 4, 3, 1, 2, 3, 3, 3, 1, 2, 4, 1, 4, 2, 3, 1, 3, 4, 4, 1, 2, 3, 4, 3, 3, 2, 4, 2, 3, 1, 2, 3, 3, 2, 2, 3, 4, 2, 1, 2, 3, 1, 4, 1, 2, 3, 2, 3, 1, 1, 3, 3, 4, 2, 3, 2, 4, 1, 2, 3, 4, 2, 3, 1, 2, 3, 4, 1, 2, 4, 3, 1, 2, 4, 1, 2, 4, 1, 2, 4, 2, 3, 1, 2, 1, 2, 1, 3, 1, 2, 4, 2, 2, 4, 2, 2, 1, 2, 4, 3, 4, 2, 1, 2, 1, 3, 4, 2, 1, 2, 3, 4, 3, 2, 3, 3, 1, 1, 1, 2, 4, 4, 1, 1, 2, 3, 2, 3, 1, 2, 3, 3, 4, 4, 2, 4, 3, 4, 2, 1, 2, 3, 4, 1, 2, 1, 3, 1, 2, 3, 2, 1, 1, 3, 1, 2, 3, 1, 2, 3, 4, 2, 2, 3, 1, 2, 4, 1, 4, 3, 1, 1, 1, 2, 3, 1, 2, 4, 1, 2, 3, 1, 2, 1, 4, 3, 1, 1, 1, 4, 3, 4, 1, 2, 3, 1, 2, 3, 4, 2, 1, 2, 1, 2, 3, 4, 3, 1, 2, 3, 1, 4, 4, 3, 2, 4, 1, 4, 1, 2, 3, 4, 2, 2, 2, 2, 2, 3, 1, 2, 1, 2, 3], \"Freq\": [0.4706089572886707, 0.10457976828637128, 0.4183190731454851, 0.8471820291235109, 0.9747422417404998, 0.19460070102131938, 0.45406830238307855, 0.19460070102131938, 0.06486690034043979, 0.8327804470088838, 0.07684216792697962, 0.15368433585395924, 0.15368433585395924, 0.614737343415837, 0.9496922023302483, 0.24571697159072023, 0.1638113143938135, 0.49143394318144046, 0.7397756786897469, 0.8951786744990881, 0.9575621404860505, 0.878077234310712, 0.09242918255902233, 0.9869692885656217, 0.014730884903964504, 0.770224623906761, 0.17774414397848332, 0.7397751300336036, 0.8081319449958319, 0.1346886574993053, 0.871608697754012, 0.8852156258323319, 0.9502075992868868, 0.8558670855846989, 0.12226672651209984, 0.10495305554157752, 0.7346713887910427, 0.10495305554157752, 0.8872892755229831, 0.9502022715089519, 0.8897966666874331, 0.24931055696433213, 0.49862111392866426, 0.1495863341785993, 0.04986211139286643, 0.9524343825870997, 0.8852138940850866, 0.9332036505456771, 0.8872862746975373, 0.3232062893118727, 0.5386771488531211, 0.4527215365052446, 0.11318038412631115, 0.39613134444208903, 0.09480089393144582, 0.2844026817943375, 0.568805363588675, 0.8868048275016753, 0.9086367523950639, 0.056789797024691495, 0.9763834520562272, 0.30380739084510494, 0.4860918253521679, 0.060761478169020985, 0.12152295633804197, 0.8955495929847196, 0.09950551033163552, 0.8872901131875146, 0.7397772889392951, 0.16132293985228047, 0.8066146992614023, 0.9741210792692584, 0.8978420577555444, 0.9930289731647733, 0.9856784785701409, 0.26605284035971793, 0.6207899608393419, 0.08868428011990598, 0.08868428011990598, 0.9153825231636652, 0.9502073955480476, 0.9763882237070292, 0.9311025394185722, 0.8280558334278578, 0.16201563536100164, 0.3240312707220033, 0.48604690608300494, 0.05400521178700055, 0.8852164175797106, 0.9311009302284722, 0.8675580748331093, 0.12852712219749768, 0.7397746035905525, 0.986856167959781, 0.08861404099707332, 0.35445616398829327, 0.5316842459824399, 0.1811389718075531, 0.7245558872302124, 0.34299660227655415, 0.6173938840977975, 0.5120874591732751, 0.08534790986221252, 0.4267395493110626, 0.8493141381788585, 0.7848860328799062, 0.08261958240841118, 0.04130979120420559, 0.12392937361261676, 0.8852175178944967, 0.9128270196664905, 0.2905809161306737, 0.697394198713617, 0.7359606796854233, 0.21027447991012096, 0.07945822924862356, 0.715124063237612, 0.15891645849724712, 0.739772544917875, 0.996310112581147, 0.4227176512157902, 0.5283970640197377, 0.052839706401973774, 0.931772499815826, 0.060442020892331985, 0.18132606267699594, 0.7253042507079838, 0.9332107491403933, 0.8872869988810653, 0.812278137754609, 0.09025312641717878, 0.04512656320858939, 0.8619346249384511, 0.09577051388205012, 0.97068801182876, 0.5215336286043886, 0.4172269028835109, 0.9280156400318657, 0.8872883922162594, 0.12283681314828859, 0.8598576920380202, 0.8877945483472486, 0.8872907206820836, 0.5093445494960674, 0.13891214986256387, 0.0926080999083759, 0.23152024977093977, 0.11354414668885035, 0.7948090268219524, 0.354078686707946, 0.354078686707946, 0.1062236060123838, 0.177039343353973, 0.8784241532399092, 0.054901509577494324, 0.054901509577494324, 0.8928140266355286, 0.9259442427869192, 0.010522093668033174, 0.06313256200819904, 0.8338163009499817, 0.04388506847105167, 0.131655205413155, 0.26192012025320316, 0.6984536540085418, 0.9502100688174473, 0.8081281518597067, 0.1346880253099511, 0.8780777018124856, 0.09242923176973532, 0.2189514252872384, 0.7663299885053344, 0.9489865820349553, 0.8852135843321528, 0.9437561969282732, 0.04603688765503772, 0.02301844382751886, 0.9976563478329917, 0.8877978013149946, 0.9304114187301867, 0.8327790882061505, 0.8868073017567846, 0.8450726237261086, 0.1469691519523667, 0.9740937757068178, 0.8852112607273908, 0.7415816702111201, 0.8898004670514484, 0.9706831618604048, 0.8868082994571661, 0.3513885933096914, 0.07027771866193828, 0.491944030633568, 0.9524368728723792, 0.09133559510927186, 0.09133559510927186, 0.7306847608741749, 0.09133559510927186, 0.9280239672790777, 0.2248403405776474, 0.7869411920217659, 0.7397755616680209, 0.9693352973598642, 0.9575535688515581, 0.976384616360925, 0.9677173886310793, 0.8872865292179808, 0.930410337400505, 0.9763893274063548, 0.10397051465175129, 0.10397051465175129, 0.7277936025622591, 0.9204819222601819, 0.08368017475092562, 0.021411203584591938, 0.9635041613066371, 0.021411203584591938, 0.7397754703064855, 0.8493150520140053, 0.8872887762070926, 0.1631786715984999, 0.8158933579924996, 0.8471806699965432, 0.7415865331296118, 0.9677181097212142, 0.9344976889518591, 0.023961479203893826, 0.023961479203893826, 0.023961479203893826, 0.899457773728785, 0.06918905951759885, 0.9575579428585829, 0.8471775556657347, 0.23268154126366042, 0.15512102750910695, 0.5429235962818744, 0.9524368244150524, 0.9332092296288973, 0.9225064329678867, 0.06589331664056333, 0.20406637071298386, 0.7142322974954435, 0.10203318535649193, 0.4567155393976151, 0.0761192565662692, 0.0761192565662692, 0.38059628283134594, 0.9317726425885209, 0.8877973035535012, 0.9280220653014756, 0.9293320573024494, 0.029041626790701543, 0.029041626790701543, 0.8224509763786245, 0.13707516272977074, 0.9175187454523037, 0.970689937109094, 0.956471848050148, 0.6122418947622472, 0.3339501244157712, 0.0556583540692952, 0.8922214837471367, 0.04461107418735684, 0.04461107418735684, 0.10428328502880817, 0.10428328502880817, 0.7821246377160612, 0.9763895240169593, 0.9317769516831755, 0.17387873114257232, 0.7534745016178134, 0.8852113105103365, 0.9056674833678952, 0.9056673634656367, 0.970686911794017, 0.9656715000980595, 0.7426901952172983, 0.18567254880432457, 0.1317442895269794, 0.1317442895269794, 0.7245935923983866, 0.09029641504520329, 0.7223713203616263, 0.09029641504520329, 0.09029641504520329, 0.9524385954449229, 0.9475412510681421, 0.05922132819175888, 0.7783249004797183, 0.08339195362282696, 0.1111892714971026, 0.02779731787427565, 0.9330116374165661, 0.9790696482845731, 0.18262091255551735, 0.7304836502220694, 0.18114011358074325, 0.724560454322973, 0.8493137143641636, 0.847183848657014, 0.9317692597532413, 0.9502056096353326, 0.9706898818149587, 0.8493138490854445, 0.4024367401842722, 0.1609746960737089, 0.3219493921474178, 0.08048734803685445, 0.9789392617860139, 0.8897986290023152, 0.913750940663692, 0.8868008340519092, 0.11354392183583742, 0.7948074528508619, 0.13211373367821275, 0.7926824020692764, 0.11123757724748824, 0.7786630407324177, 0.11123757724748824], \"Term\": [\"ability\", \"ability\", \"ability\", \"aerial\", \"algorithm\", \"although\", \"although\", \"although\", \"although\", \"amboise\", \"american\", \"american\", \"american\", \"american\", \"anatomy\", \"animal\", \"animal\", \"animal\", \"apartment\", \"aphelocoma\", \"application\", \"approach\", \"approach\", \"artificial\", \"artificial\", \"artist\", \"artist\", \"ascent\", \"battle\", \"battle\", \"billed\", \"bottom\", \"breeding\", \"brother\", \"brother\", \"building\", \"building\", \"building\", \"caledonian\", \"carrion\", \"caterina\", \"century\", \"century\", \"century\", \"century\", \"christ\", \"chrysler\", \"classifier\", \"collared\", \"common\", \"common\", \"company\", \"company\", \"company\", \"completed\", \"completed\", \"completed\", \"composition\", \"computer\", \"computer\", \"computing\", \"considered\", \"considered\", \"considered\", \"considered\", \"construction\", \"construction\", \"context\", \"contract\", \"copyright\", \"copyright\", \"corvid\", \"corvidae\", \"corvids\", \"corvus\", \"created\", \"created\", \"created\", \"created\", \"cyanocorax\", \"cyanolyca\", \"cybersecurity\", \"decision\", \"dendrocitta\", \"design\", \"design\", \"design\", \"design\", \"diameter\", \"diplomacy\", \"drawing\", \"drawing\", \"edison\", \"eiffel\", \"emotion\", \"emotion\", \"emotion\", \"emotional\", \"emotional\", \"engineer\", \"engineer\", \"environment\", \"environment\", \"environment\", \"eurasian\", \"example\", \"example\", \"example\", \"example\", \"exploitation\", \"exposition\", \"family\", \"family\", \"famous\", \"famous\", \"figure\", \"figure\", \"figure\", \"fitted\", \"florence\", \"france\", \"france\", \"france\", \"francis\", \"french\", \"french\", \"french\", \"future\", \"garrulus\", \"general\", \"general\", \"general\", \"genius\", \"genius\", \"google\", \"government\", \"government\", \"gustave\", \"habitat\", \"height\", \"height\", \"historian\", \"holarctic\", \"however\", \"however\", \"however\", \"however\", \"hydraulic\", \"hydraulic\", \"including\", \"including\", \"including\", \"including\", \"information\", \"information\", \"information\", \"installed\", \"intelligence\", \"intelligence\", \"intelligence\", \"intelligent\", \"intelligent\", \"intelligent\", \"interest\", \"interest\", \"jackdaw\", \"journal\", \"journal\", \"knowledge\", \"knowledge\", \"landscape\", \"landscape\", \"language\", \"lattice\", \"learning\", \"learning\", \"learning\", \"leonardo\", \"lifetime\", \"lineage\", \"lorenzo\", \"ludovico\", \"machine\", \"machine\", \"magpie\", \"maintenance\", \"mammal\", \"manuscript\", \"market\", \"medici\", \"member\", \"member\", \"member\", \"michelangelo\", \"million\", \"million\", \"million\", \"million\", \"minute\", \"monument\", \"monument\", \"mounted\", \"network\", \"neural\", \"neuron\", \"notebook\", \"nucifraga\", \"nutcracker\", \"optimization\", \"original\", \"original\", \"original\", \"painter\", \"painter\", \"painting\", \"painting\", \"painting\", \"passenger\", \"passerine\", \"perisoreus\", \"personality\", \"personality\", \"pillar\", \"podoces\", \"portrait\", \"problem\", \"problem\", \"problem\", \"problem\", \"process\", \"process\", \"program\", \"protest\", \"public\", \"public\", \"public\", \"quality\", \"question\", \"reasoning\", \"reasoning\", \"received\", \"received\", \"received\", \"related\", \"related\", \"related\", \"related\", \"remains\", \"renaissance\", \"replaced\", \"research\", \"research\", \"research\", \"researcher\", \"researcher\", \"restaurant\", \"robotics\", \"russia\", \"scientific\", \"scientific\", \"scientific\", \"search\", \"search\", \"search\", \"second\", \"second\", \"second\", \"security\", \"sforza\", \"social\", \"social\", \"soci\\u00e9t\\u00e9\", \"software\", \"solution\", \"solving\", \"specie\", \"structural\", \"structural\", \"structure\", \"structure\", \"structure\", \"subject\", \"subject\", \"subject\", \"subject\", \"supper\", \"symbolic\", \"symbolic\", \"system\", \"system\", \"system\", \"system\", \"tallest\", \"technology\", \"television\", \"television\", \"territory\", \"territory\", \"throated\", \"transmitter\", \"treatise\", \"treepie\", \"turing\", \"urocissa\", \"various\", \"various\", \"various\", \"various\", \"vasari\", \"venice\", \"verrocchio\", \"virgin\", \"visitor\", \"visitor\", \"workshop\", \"workshop\", \"writing\", \"writing\", \"writing\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el591401758885387043567194330\", ldavis_el591401758885387043567194330_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el591401758885387043567194330\", ldavis_el591401758885387043567194330_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el591401758885387043567194330\", ldavis_el591401758885387043567194330_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pwEz8DHJ1ve"
      },
      "source": [
        "Cada círculo na imagem acima corresponde a um tópico.\n",
        "\n",
        ">\n",
        "A distância entre os círculos mostra como os tópicos são diferentes uns dos outros. Os círculos também podem estar sobrepostos, indicando que os tópicos têm muitas palavras em comum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhBxsShCMRf-"
      },
      "source": [
        "Se você passar o mouse sobre qualquer palavra à direita, verá apenas o círculo do tópico que contém a palavra. Uma palavra pode estar relacionada a mais de um tópico, assim mais de um círculo aparecerá."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPNGTTbkM_3q"
      },
      "source": [
        "Da mesma forma, se você clicar em qualquer um dos círculos, uma lista dos termos mais frequentes para aquele tópico aparecerá à direita junto com a frequência de ocorrência naquele mesmo tópico."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aPSmR7NZe2n"
      },
      "source": [
        "**Mais informações:**\n",
        "\n",
        "> https://stackabuse.com/python-for-nlp-working-with-the-gensim-library-part-2/"
      ]
    }
  ]
}